{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)\n",
    "from sklearn import metrics\n",
    "\n",
    "import os\n",
    "os.chdir('/home/aremirata/repos/7mw/')\n",
    "\n",
    "from savvyworkout import lstm_preprocess\n",
    "from savvyworkout import triaxial_lstm\n",
    "from savvyworkout import triaxial_deepconvlstm\n",
    "from savvyworkout import deeplearning_utils\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Masking, TimeDistributed, MaxPooling1D, Flatten\n",
    "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras import backend as K\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras.utils import np_utils\n",
    "from sklearn.externals import joblib\n",
    "from keras.callbacks import History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/aremirata/repos/LSTM-Human-Activity-Recognition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Dataset Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope,3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz were captured. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion on what is LSTM is found on this notebook: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aremirata/repos/LSTM-Human-Activity-Recognition\n",
      "data\t LSTM_files  lstm.py\tUCI ActivityRecognition.ipynb\n",
      "LICENSE  LSTM.ipynb  README.md\n",
      "/home/aremirata/repos/LSTM-Human-Activity-Recognition/data\n",
      "download_dataset.py  __MACOSX  source.txt  UCI HAR Dataset  UCI HAR Dataset.zip\n",
      "\n",
      "Downloading...\n",
      "Dataset already downloaded. Did not download twice.\n",
      "\n",
      "Extracting...\n",
      "Dataset already extracted. Did not extract twice.\n",
      "\n",
      "/home/aremirata/repos/LSTM-Human-Activity-Recognition/data\n",
      "download_dataset.py  __MACOSX  source.txt  UCI HAR Dataset  UCI HAR Dataset.zip\n",
      "/home/aremirata/repos/LSTM-Human-Activity-Recognition\n",
      "data\t LSTM_files  lstm.py\tUCI ActivityRecognition.ipynb\n",
      "LICENSE  LSTM.ipynb  README.md\n",
      "\n",
      "Dataset is now located at: data/UCI HAR Dataset/\n"
     ]
    }
   ],
   "source": [
    "# Note: Linux bash commands start with a \"!\" inside those \"ipython notebook\" cells\n",
    "\n",
    "DATA_PATH = \"data/\"\n",
    "\n",
    "!pwd && ls\n",
    "os.chdir(DATA_PATH)\n",
    "!pwd && ls\n",
    "\n",
    "!python download_dataset.py\n",
    "\n",
    "!pwd && ls\n",
    "os.chdir(\"..\")\n",
    "!pwd && ls\n",
    "\n",
    "DATASET_PATH = DATA_PATH + \"UCI HAR Dataset/\"\n",
    "print(\"\\n\" + \"Dataset is now located at: \" + DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Useful Constants\n",
    "\n",
    "# Those are separate normalised input features for the neural network\n",
    "INPUT_SIGNAL_TYPES = [\n",
    "    \"total_acc_x_\",\n",
    "    \"total_acc_y_\",\n",
    "    \"total_acc_z_\"\n",
    "]\n",
    "\n",
    "# Output classes to learn how to classify\n",
    "LABELS = [\n",
    "    \"WALKING\", \n",
    "    \"WALKING_UPSTAIRS\", \n",
    "    \"WALKING_DOWNSTAIRS\", \n",
    "    \"SITTING\", \n",
    "    \"STANDING\", \n",
    "    \"LAYING\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = \"train/\"\n",
    "TEST = \"test/\"\n",
    "\n",
    "\n",
    "# Load \"X\" (the neural network's training and testing inputs)\n",
    "\n",
    "def load_X(X_signals_paths):\n",
    "    X_signals = []\n",
    "    \n",
    "    for signal_type_path in X_signals_paths:\n",
    "        file = open(signal_type_path, 'r')\n",
    "        # Read dataset from disk, dealing with text files' syntax\n",
    "        X_signals.append(\n",
    "            [np.array(serie, dtype=np.float32) for serie in [\n",
    "                row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "            ]]\n",
    "        )\n",
    "        file.close()\n",
    "    \n",
    "    return np.transpose(np.array(X_signals), (1, 2, 0))\n",
    "\n",
    "X_train_signals_paths = [\n",
    "    DATASET_PATH + TRAIN + \"Inertial Signals/\" + signal + \"train.txt\" for signal in INPUT_SIGNAL_TYPES\n",
    "]\n",
    "X_test_signals_paths = [\n",
    "    DATASET_PATH + TEST + \"Inertial Signals/\" + signal + \"test.txt\" for signal in INPUT_SIGNAL_TYPES\n",
    "]\n",
    "\n",
    "X_train = load_X(X_train_signals_paths)\n",
    "X_test = load_X(X_test_signals_paths)\n",
    "\n",
    "\n",
    "# Load \"y\" (the neural network's training and testing outputs)\n",
    "\n",
    "def load_y(y_path):\n",
    "    file = open(y_path, 'r')\n",
    "    # Read dataset from disk, dealing with text file's syntax\n",
    "    y_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "        ]], \n",
    "        dtype=np.int32\n",
    "    )\n",
    "    file.close()\n",
    "    \n",
    "    # Substract 1 to each output class for friendly 0-based indexing \n",
    "    return y_ - 1\n",
    "\n",
    "y_train_path = DATASET_PATH + TRAIN + \"y_train.txt\"\n",
    "y_test_path = DATASET_PATH + TEST + \"y_test.txt\"\n",
    "\n",
    "y_train = load_y(y_train_path)\n",
    "y_test = load_y(y_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 128, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947, 128, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = np.linalg.norm(X_train, axis=-1)\n",
    "testing_data = np.linalg.norm(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()\n",
    "x_test = testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(training_data, y_train, \n",
    "                                                    test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class custom_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        logs[\"roc-auc\"] = roc\n",
    "        logs[\"roc-auc_val\"] = roc_val\n",
    "        return\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_train)), len(np.unique(y_test)), len(np.unique(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, 6)\n",
    "y_test = keras.utils.to_categorical(y_test, 6)\n",
    "y_val = keras.utils.to_categorical(y_val, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=128)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=128)\n",
    "x_val = sequence.pad_sequences(x_val, maxlen=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 6\n",
    "epochs = 20\n",
    "data_augmentation = True\n",
    "num_predictions = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aremirata/anaconda3/envs/t2d_pred/lib/python3.5/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(kernel_initializer=\"uniform\", recurrent_initializer=\"uniform\", recurrent_activation=\"sigmoid\", input_shape=(128,), return_sequences=True, units=10, unit_forget_bias=True, activation=\"tanh\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/aremirata/anaconda3/envs/t2d_pred/lib/python3.5/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(unit_forget_bias=True, recurrent_initializer=\"uniform\", kernel_initializer=\"uniform\", recurrent_activation=\"sigmoid\", units=10, return_sequences=True, activation=\"tanh\")`\n",
      "/home/aremirata/anaconda3/envs/t2d_pred/lib/python3.5/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(unit_forget_bias=True, recurrent_initializer=\"uniform\", kernel_initializer=\"uniform\", recurrent_activation=\"sigmoid\", units=10, activation=\"tanh\")`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(128, 100))\n",
    "model.add(LSTM(output_dim=10,\n",
    "                       init='uniform',\n",
    "                       inner_init='uniform',\n",
    "                       forget_bias_init='one',\n",
    "                       activation='tanh',\n",
    "                       inner_activation='sigmoid',\n",
    "                       input_shape=x_train.shape[1:],\n",
    "                       return_sequences=True))\n",
    "model.add(LSTM(output_dim=10,\n",
    "               init='uniform',\n",
    "               inner_init='uniform',\n",
    "               forget_bias_init='one',\n",
    "               activation='tanh',\n",
    "               inner_activation='sigmoid',\n",
    "               return_sequences=True))\n",
    "model.add(LSTM(output_dim=10,\n",
    "                           init='uniform',\n",
    "                           inner_init='uniform',\n",
    "                           forget_bias_init='one',\n",
    "                           activation='tanh',\n",
    "                           inner_activation='sigmoid'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4925 samples, validate on 2427 samples\n",
      "Epoch 1/20\n",
      "roc-auc: 0.7719 - roc-auc_val: 0.7647                                                                                                    \n",
      "104s - loss: 1.5272 - acc: 0.2847 - val_loss: 1.3090 - val_acc: 0.3502\n",
      "Epoch 2/20\n",
      "roc-auc: 0.797 - roc-auc_val: 0.79                                                                                                    \n",
      "79s - loss: 1.2778 - acc: 0.3498 - val_loss: 1.2622 - val_acc: 0.3506\n",
      "Epoch 3/20\n",
      "roc-auc: 0.7988 - roc-auc_val: 0.7954                                                                                                    \n",
      "76s - loss: 1.2592 - acc: 0.3553 - val_loss: 1.2649 - val_acc: 0.3502\n",
      "Epoch 4/20\n",
      "roc-auc: 0.8157 - roc-auc_val: 0.8114                                                                                                    \n",
      "80s - loss: 1.2530 - acc: 0.3553 - val_loss: 1.2457 - val_acc: 0.3523\n",
      "Epoch 5/20\n",
      "roc-auc: 0.8285 - roc-auc_val: 0.8253                                                                                                    \n",
      "76s - loss: 1.2350 - acc: 0.3578 - val_loss: 1.2236 - val_acc: 0.3494\n",
      "Epoch 6/20\n",
      "roc-auc: 0.8369 - roc-auc_val: 0.8338                                                                                                    \n",
      "74s - loss: 1.2178 - acc: 0.3874 - val_loss: 1.1989 - val_acc: 0.4194\n",
      "Epoch 7/20\n",
      "roc-auc: 0.8364 - roc-auc_val: 0.8331                                                                                                    \n",
      "78s - loss: 1.1827 - acc: 0.4154 - val_loss: 1.1533 - val_acc: 0.4339\n",
      "Epoch 8/20\n",
      "roc-auc: 0.846 - roc-auc_val: 0.8407                                                                                                    \n",
      "79s - loss: 1.1260 - acc: 0.4465 - val_loss: 1.1205 - val_acc: 0.4524\n",
      "Epoch 9/20\n",
      "roc-auc: 0.8526 - roc-auc_val: 0.846                                                                                                    \n",
      "78s - loss: 1.0997 - acc: 0.4520 - val_loss: 1.1004 - val_acc: 0.4565\n",
      "Epoch 10/20\n",
      "roc-auc: 0.8532 - roc-auc_val: 0.85                                                                                                    \n",
      "76s - loss: 1.0844 - acc: 0.4554 - val_loss: 1.0770 - val_acc: 0.4602\n",
      "Epoch 11/20\n",
      "roc-auc: 0.8562 - roc-auc_val: 0.8503                                                                                                    \n",
      "76s - loss: 1.0671 - acc: 0.4593 - val_loss: 1.0647 - val_acc: 0.4623\n",
      "Epoch 12/20\n",
      "roc-auc: 0.8588 - roc-auc_val: 0.8569                                                                                                    \n",
      "75s - loss: 1.0662 - acc: 0.4577 - val_loss: 1.0580 - val_acc: 0.4627\n",
      "Epoch 13/20\n",
      "roc-auc: 0.8674 - roc-auc_val: 0.865                                                                                                    \n",
      "77s - loss: 1.0593 - acc: 0.4634 - val_loss: 1.0471 - val_acc: 0.4619\n",
      "Epoch 14/20\n",
      "roc-auc: 0.8632 - roc-auc_val: 0.8624                                                                                                    \n",
      "75s - loss: 1.0493 - acc: 0.4638 - val_loss: 1.0571 - val_acc: 0.4631\n",
      "Epoch 15/20\n",
      "roc-auc: 0.8686 - roc-auc_val: 0.864                                                                                                    \n",
      "80s - loss: 1.0373 - acc: 0.4664 - val_loss: 1.0457 - val_acc: 0.4644\n",
      "Epoch 16/20\n",
      "roc-auc: 0.8677 - roc-auc_val: 0.8642                                                                                                    \n",
      "76s - loss: 1.0378 - acc: 0.4719 - val_loss: 1.0383 - val_acc: 0.4681\n",
      "Epoch 17/20\n",
      "roc-auc: 0.8665 - roc-auc_val: 0.8642                                                                                                    \n",
      "75s - loss: 1.0373 - acc: 0.4682 - val_loss: 1.0278 - val_acc: 0.4681\n",
      "Epoch 18/20\n",
      "roc-auc: 0.8694 - roc-auc_val: 0.868                                                                                                    \n",
      "77s - loss: 1.0278 - acc: 0.4735 - val_loss: 1.0223 - val_acc: 0.4697\n",
      "Epoch 19/20\n",
      "roc-auc: 0.8659 - roc-auc_val: 0.8626                                                                                                    \n",
      "76s - loss: 1.0356 - acc: 0.4713 - val_loss: 1.0328 - val_acc: 0.4697\n",
      "Epoch 20/20\n",
      "roc-auc: 0.8698 - roc-auc_val: 0.867                                                                                                    \n",
      "81s - loss: 1.0262 - acc: 0.4751 - val_loss: 1.0191 - val_acc: 0.4747\n",
      "Validation loss: 1.01910890396\n",
      "Validation accuracy: 0.474660074117\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "lstm_callback = model.fit(x_train, y_train, batch_size=batch_size,\n",
    "                    verbose=2, validation_data=(x_val, y_val),\n",
    "                    epochs=epochs,\n",
    "                    callbacks = [custom_callback(\n",
    "                            training_data=(x_train, y_train),\n",
    "                            validation_data=(x_val, y_val))])\n",
    "\n",
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "    \n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])\n",
    "\n",
    "pred_test = model.predict(x_test)\n",
    "roc_score_test = roc_auc_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85674422515193516"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "t2d_pred",
   "language": "python",
   "name": "t2d_pred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
